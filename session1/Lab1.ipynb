{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2928379",
   "metadata": {},
   "source": [
    "# Lab 1: Econland\n",
    "\n",
    "### General Context\n",
    "\n",
    "Econland is a fictional country with a diverse economy comprising manufacturing, services, and finance. The economy shows cyclical patterns of expansion and contraction. Private Investment (PI) is key indicator.\n",
    "\n",
    "### Structure\n",
    "\n",
    "+ Period: 40 months (Jan 2022 - Apr 2025)\n",
    "+ Data points: 200 headlines (approx. 5 per month)\n",
    "+ Categories: Positive, Negative, Neutral\n",
    "+ Target variables: Private Investment (PI)\n",
    "\n",
    "### Example Headlines\n",
    "\n",
    "1. `Positive`: _\"Manufacturing Output Surges by 15% Amid Optimism\"_\n",
    "\n",
    "2. `Negative`: _\"Economic Uncertainty Dampens Private Investment Prospects\"_\n",
    "\n",
    "3. `Neutral`: _\"Government Releases Latest Industrial Output Data\"_\n",
    "\n",
    "### Synthetic PI Data (Hypothetical)\n",
    "\n",
    "PI will vary based on the sentiment distribution in the news corpus.\n",
    "\n",
    "The Business Confidence Index (BCI) will be derived using Zero-Shot techniques, then incorporated into a forecasting model as an exogenous variable.\n",
    "\n",
    "### Packages\n",
    "\n",
    "This notebook demonstrates the use of the `FewShotX` package (version 0.1.2), available for download [here](https://github.com/RenatoVassallo/BSE-ForecastNLP/releases/download/0.1.2/fewshotx-0.1.2-py3-none-any.whl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d160ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX import load_dataset\n",
    "\n",
    "df_corpus = load_dataset(\"econland_corpus.parquet\")\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad459ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX import Embeddings\n",
    "\n",
    "embedder = Embeddings(model_name='all-MiniLM-L6-v2')\n",
    "df_embed = embedder.embed_df(df_corpus, text_col='headline')\n",
    "df_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX.scoring.zeroshot import ZeroShotLearner\n",
    "\n",
    "labels = [\"This example is about economics or finance\"]\n",
    "\n",
    "zs1 = ZeroShotLearner(embedder.model, similarity='cosine')\n",
    "\n",
    "scored_df1 = zs1.score_df(df=df_embed.copy(),\n",
    "                        text_embedding_cols=[f\"emb_{i}\" for i in range(embedder.embedding_dim)],\n",
    "                        labels=labels,\n",
    "                        label_names=[\"is_financial_zs1\"])\n",
    "scored_df1 = scored_df1[[\"date\", \"headline\", \"category\", \"is_financial\", \"is_financial_zs1\"]]\n",
    "scored_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84eedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX import ZeroShotNLI\n",
    "\n",
    "zs2 = ZeroShotNLI()\n",
    "labels = [\"about economics or finance\"]\n",
    "scored_df2 = zs2.score_df(scored_df1, text_col=\"headline\", labels=labels, label_names=[\"is_financial_zs2\"])\n",
    "scored_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Extract relevant columns\n",
    "y_true = scored_df2[\"is_financial\"]\n",
    "y_pred1 = scored_df2[\"is_financial_zs1\"]\n",
    "y_pred2 = scored_df2[\"is_financial_zs2\"]\n",
    "\n",
    "# Function to find the optimal threshold based on F1 Score\n",
    "def optimal_threshold(y_true, y_pred):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-9)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Calculate optimal thresholds\n",
    "threshold1 = optimal_threshold(y_true, y_pred1)\n",
    "threshold2 = optimal_threshold(y_true, y_pred2)\n",
    "\n",
    "print(f\"Optimal Threshold for ZS1: {threshold1:.4f}\")\n",
    "print(f\"Optimal Threshold for ZS2: {threshold2:.4f}\")\n",
    "\n",
    "# Generate predictions using optimal thresholds\n",
    "scored_df2[\"pred_zs1\"] = (y_pred1 >= threshold1).astype(int)\n",
    "scored_df2[\"pred_zs2\"] = (y_pred2 >= threshold2).astype(int)\n",
    "\n",
    "# Save the scored DataFrame\n",
    "#scored_df2.to_excel(\"scored_df.xlsx\", index=False)\n",
    "scored_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX import evaluate_predictions\n",
    "\n",
    "evaluate_predictions(\n",
    "    y_true=scored_df2[\"is_financial\"], \n",
    "    ZS1=scored_df2[\"is_financial_zs1\"], \n",
    "    ZS2=scored_df2[\"is_financial_zs2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7559dd4",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "+ X-axis (Recall): How many of the true positives your model is capturing (sensitivity).\n",
    "+ Y-axis (Precision): How many of the predicted positives are actually true positives.\n",
    "\n",
    "A PR Curve is particularly useful when dealing with imbalanced datasets, as it focuses on true positives and avoids misleading impressions from true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e52abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives\n",
    "scored_df2[(scored_df2[\"is_financial\"] == 0) & (scored_df2[\"pred_zs1\"] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d4736b",
   "metadata": {},
   "source": [
    "## 2. Building a Business Confidence Indicator (BCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84188b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FewShotX import ZeroShotNLI\n",
    "\n",
    "zs2 = ZeroShotNLI()\n",
    "labels = [\"Positive business confidence\", \n",
    "          \"Neutral business confidence\",\n",
    "          \"Negative business confidence\"]\n",
    "scored_df3 = zs2.score_df(scored_df1, text_col=\"headline\", labels=labels, label_names=[\"positive\", \"neutral\", \"negative\"])\n",
    "scored_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold_zs1 = 0.5635  # Optimal threshold based on F1 score\n",
    "weights = {\"positive\": 1, \"neutral\": 0.0, \"negative\": -1}\n",
    "\n",
    "# Predict Financial/Economic Relevance\n",
    "scored_df3['date'] = pd.to_datetime(scored_df3['date'])\n",
    "scored_df3['pred_zs1'] = (scored_df3['is_financial_zs1'] >= threshold_zs1).astype(int)\n",
    "\n",
    "# Determine Sentiment Score for Each Headline\n",
    "scored_df3['max_sentiment'] = scored_df3[['positive', 'neutral', 'negative']].idxmax(axis=1)\n",
    "# Assign sentiment score using weights\n",
    "scored_df3['sentiment_score'] = scored_df3.apply(lambda row: row[row['max_sentiment']] * weights[row['max_sentiment']], axis=1) \n",
    "scored_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Ensure the strings are lowercase\n",
    "scored_df3['category'] = scored_df3['category'].str.lower()\n",
    "scored_df3['max_sentiment'] = scored_df3['max_sentiment'].str.lower()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(scored_df3['category'], scored_df3['max_sentiment'], labels=[\"positive\", \"neutral\", \"negative\"])\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Positive\", \"Neutral\", \"Negative\"])\n",
    "disp.plot(cmap=\"Blues\", colorbar=True)\n",
    "disp.ax_.set_title(\"Confusion Matrix: Ground Truth vs Predicted Sentiment\")\n",
    "disp.ax_.set_xlabel(\"Predicted\")\n",
    "disp.ax_.set_ylabel(\"True Label\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a582ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only financial/economic headlines\n",
    "financial_df = scored_df3[scored_df3['pred_zs1'] == 1].copy()\n",
    "financial_df['date'] = financial_df['date'].dt.to_period('M')\n",
    "\n",
    "# Monthly BCI as the mean of sentiment scores\n",
    "monthly_bci = financial_df.groupby('date')['sentiment_score'].mean()\n",
    "\n",
    "# Ensure all months are included, initializing missing months with zero\n",
    "all_months = pd.period_range(start=financial_df['date'].min(), end=financial_df['date'].max(), freq='M')\n",
    "monthly_bci = monthly_bci.reindex(all_months, fill_value=0)\n",
    "\n",
    "# Normalize BCI (optional, for standardization)\n",
    "monthly_bci = (monthly_bci - monthly_bci.mean()) / monthly_bci.std()\n",
    "monthly_bci = monthly_bci.reset_index().rename(columns={'index': 'date', 'sentiment_score': 'BCI'})\n",
    "monthly_bci.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c91d3",
   "metadata": {},
   "source": [
    "## Business confidence and private investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_investment = pd.read_parquet(\"datasets/econland_investment.parquet\")\n",
    "df_investment['investment_growth'] = df_investment['investment_growth'] * 100\n",
    "df_merge = pd.merge(monthly_bci, df_investment, on=\"date\", how=\"left\")\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ecdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Set the date as the index for plotting\n",
    "df_merge['date'] = df_merge['date'].dt.to_timestamp()\n",
    "df_merge.set_index('date', inplace=True)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Plot the investment growth\n",
    "ax1.plot(df_merge.index, df_merge['investment_growth'], color='blue', label='Investment Growth', linewidth=2)\n",
    "ax1.set_ylabel('Investment Growth', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Create a second y-axis for the BCI\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_merge.index, df_merge['BCI'], color='orange', label='Business Confidence Index (BCI)', linewidth=2)\n",
    "ax2.set_ylabel('Business Confidence Index (BCI)', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "ax1.grid(True, which='both', linestyle='--', alpha=0.7)\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('Investment Growth and Business Confidence Index (BCI) Over Time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ca4c4",
   "metadata": {},
   "source": [
    "# Forecasting with text as data\n",
    "\n",
    "We will:\n",
    "\n",
    "+ Expore if BCI is a lead or lag variable of investment.\n",
    "+ Estimate a benchmark time series model: AR(1).\n",
    "+ Evaluate performance in a rolling window setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a71b02",
   "metadata": {},
   "source": [
    "## 2.1 Dynamic correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def dynamic_correlation_plot(df, fix_var, dyn_var, max_lag=8):\n",
    "    \"\"\"\n",
    "    Plot dynamic linear correlation between a fixed and a dynamic variable over varying lags.\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    lags = range(max_lag, -(max_lag+1), -1)\n",
    "\n",
    "    for lag in lags:\n",
    "        # Shift variable\n",
    "        shifted_bci = df[dyn_var].shift(lag)\n",
    "        # Compute correlation, dropping NaN values\n",
    "        corr = df[fix_var].corr(shifted_bci)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    # Identify the maximum correlation and corresponding lag\n",
    "    max_corr_idx = np.argmax(np.abs(correlations))\n",
    "    best_lag = lags[max_corr_idx]\n",
    "    best_corr = correlations[max_corr_idx]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(lags, correlations, marker='o', linestyle='-', label='Correlation')\n",
    "    plt.axvline(x=best_lag, color='red', linestyle='--', label=f'Max Corr Lag: {best_lag} (Corr: {best_corr:.2f})')\n",
    "    plt.title(\"Dynamic Correlation\")\n",
    "    plt.xlabel(\"Lag (periods)\")\n",
    "    plt.ylabel(\"Correlation\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Interpretation\n",
    "    if best_lag < 0:\n",
    "        print(f\"The dynamic variable '{dyn_var}' lags the fixed variable '{fix_var}' by {abs(best_lag)} periods. Max correlation: {best_corr:.2f}\")\n",
    "    elif best_lag > 0:\n",
    "        print(f\"The dynamic variable '{dyn_var}' leads the fixed variable '{fix_var}' by {best_lag} periods. Max correlation: {best_corr:.2f}\")\n",
    "    else:\n",
    "        print(f\"The dynamic variable '{dyn_var}' and the fixed variable '{fix_var}' are synchronized with a correlation of {best_corr:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ced870",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_correlation_plot(df_merge.copy(), 'investment_growth', 'BCI', max_lag=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745145a2",
   "metadata": {},
   "source": [
    "## 2.2 Estimate an AR(1) model for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dependent variable (Y)\n",
    "lags = 1\n",
    "train_data = df_merge.copy()\n",
    "Y = train_data['investment_growth'].values[lags:].reshape(-1, 1)\n",
    "print(\"Y matrix: \\n\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the lagged variable (X)\n",
    "X = np.array([train_data['investment_growth'].shift(i).dropna().values for i in range(1, lags + 1)]).T\n",
    "# Add constant (intercept) column\n",
    "X = np.hstack((np.ones_like(X[:, 0]).reshape(-1, 1), X))\n",
    "print(\"X matrix: \\n\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows in X\n",
    "T = X.shape[0]\n",
    "print('# Observations of Y: ', Y.shape[0])\n",
    "print('# Observations of X: ', T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS \n",
    "b0 = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n",
    "b0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4bd99",
   "metadata": {},
   "source": [
    "## Rolling forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def ar_forecast_with_lags(df, start_date, end_date, lags=1, exog_variable=None):\n",
    "    \"\"\"\n",
    "    Perform AR forecasting with specified number of lags and an optional exogenous variable.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    start_date (str): Start date of the forecast period in 'YYYY-MM' format.\n",
    "    end_date (str): End date of the forecast period in 'YYYY-MM' format.\n",
    "    lags (int): Number of lags to use in the AR model (default is 1).\n",
    "    exog_variable (str or None): The name of the exogenous variable to include in the model (default is None).\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the forecasts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the date column is datetime and sorted\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['date']):\n",
    "        raise TypeError(\"The 'date' column must be a datetime type.\")\n",
    "\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    # Initialize an empty list for predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over the forecast period\n",
    "    for forecast_period in pd.period_range(start=start_date, end=end_date, freq='M'):\n",
    "        # Convert the Period object to a Timestamp object\n",
    "        forecast_date = forecast_period.to_timestamp()\n",
    "\n",
    "        # Define the training window\n",
    "        train_data = df[df['date'] <= forecast_date]\n",
    "        \n",
    "        # Ensure we have sufficient data points for estimation\n",
    "        if len(train_data) < lags + 1:\n",
    "            print(f\"Insufficient data for {forecast_date}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract the dependent variable (Y)\n",
    "        Y = train_data['investment_growth'].values[lags:].reshape(-1, 1)\n",
    "\n",
    "        # Extract the lagged variable (X)\n",
    "        X = np.array([train_data['investment_growth'].shift(i).dropna().values for i in range(1, lags + 1)]).T\n",
    "\n",
    "        # Include exogenous variable if specified\n",
    "        if exog_variable:\n",
    "            # Ensure the exog variable has the correct number of observations\n",
    "            exog_data = train_data[exog_variable].shift(1).dropna().values.reshape(-1, 1)\n",
    "            if len(exog_data) == len(X):\n",
    "                X = np.hstack([X, exog_data])\n",
    "            else:\n",
    "                print(f\"Exog variable length mismatch at {forecast_date}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        # Add constant (intercept) column\n",
    "        X = np.hstack((np.ones_like(X[:, 0]).reshape(-1, 1), X))\n",
    "\n",
    "        # Estimate OLS parameters\n",
    "        try:\n",
    "            b0 = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(f\"Singular matrix error at {forecast_date}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Extract the most recent observation for forecasting\n",
    "        last_obs = train_data['investment_growth'].iloc[-1]\n",
    "        X_forecast = np.array([1] + [last_obs] * lags)\n",
    "\n",
    "        if exog_variable:\n",
    "            # Include the latest exog value if specified\n",
    "            exog_value = train_data[exog_variable].iloc[-1]\n",
    "            X_forecast = np.hstack([X_forecast, exog_value])\n",
    "\n",
    "        X_forecast = X_forecast.reshape(1, -1)\n",
    "\n",
    "        # Forecast one step ahead\n",
    "        forecast = X_forecast @ b0\n",
    "\n",
    "        # Store the prediction as a dictionary\n",
    "        # apprend predictions for \"date\" the forecast_date + 1 month:\n",
    "        predictions.append({\n",
    "            'date': forecast_date + pd.offsets.MonthBegin(1),\n",
    "            'forecast': forecast.item()  # Extract scalar value\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "    # Merge the predictions back to the original dataset\n",
    "    df = df.merge(predictions_df, on='date', how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_forecasts(df_actual, df_forecast_1, df_forecast_2):\n",
    "    \"\"\"\n",
    "    Plot actual vs. predicted values for two different forecasts.\n",
    "    \n",
    "    Parameters:\n",
    "    df_actual (pd.DataFrame): DataFrame containing actual values.\n",
    "    df_forecast_1 (pd.DataFrame): DataFrame containing first forecast values (e.g., AR(1) without BCI).\n",
    "    df_forecast_2 (pd.DataFrame): DataFrame containing second forecast values (e.g., AR(1) with BCI).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_actual['date'], df_actual['investment_growth'], label='Actual', color='black', linestyle='--', linewidth=2)\n",
    "    plt.plot(df_forecast_1['date'], df_forecast_1['forecast'], label='AR(1) Forecast', color='blue', linestyle='-', linewidth=2)\n",
    "    plt.plot(df_forecast_2['date'], df_forecast_2['forecast'], label='AR(1) with BCI Forecast', color='red', linestyle='-', linewidth=2)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Investment Growth')\n",
    "    plt.title('Actual vs. Forecasted Investment Growth')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_metrics(df_actual, df_forecast):\n",
    "    \"\"\"\n",
    "    Calculate RMSE and MAE between actual and forecasted values.\n",
    "\n",
    "    Parameters:\n",
    "    df_actual (pd.DataFrame): DataFrame containing actual values.\n",
    "    df_forecast (pd.DataFrame): DataFrame containing forecasted values.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing RMSE and MAE.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Merge actual and forecast data\n",
    "    df_merged = pd.merge(df_actual, df_forecast[['date', 'forecast']], on='date', how='left')\n",
    "    \n",
    "    # Drop rows with NaN values in the 'forecast' column\n",
    "    df_merged = df_merged.dropna(subset=['forecast'])\n",
    "    \n",
    "    # Calculate RMSE and MAE\n",
    "    rmse = np.sqrt(mean_squared_error(df_merged['investment_growth'], df_merged['forecast']))\n",
    "    mae = mean_absolute_error(df_merged['investment_growth'], df_merged['forecast'])\n",
    "\n",
    "    return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "def print_metrics(metrics_dict, title):\n",
    "    \"\"\"\n",
    "    Print the metrics in a formatted manner.\n",
    "\n",
    "    Parameters:\n",
    "    metrics_dict (dict): Dictionary containing RMSE and MAE.\n",
    "    title (str): Title for the metrics (e.g., \"AR(1) without BCI\").\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"{title:^50}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {metrics_dict['RMSE']:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {metrics_dict['MAE']:.4f}\")\n",
    "    print(f\"{'=' * 50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4014be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the date column is datetime and sorted\n",
    "df_merge.reset_index(drop=False, inplace=True)\n",
    "df_base = df_merge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AR(1) with BCI\n",
    "df_without_bci = ar_forecast_with_lags(df_base, start_date=\"2023-01\", end_date=\"2025-04\", lags=1)\n",
    "\n",
    "# For AR(1) with BCI\n",
    "df_with_bci = ar_forecast_with_lags(df_base, start_date=\"2023-01\", end_date=\"2025-04\", lags=1, exog_variable=\"BCI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both forecasts with actual values\n",
    "plot_forecasts(df_base, df_without_bci, df_with_bci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for both forecasts\n",
    "metrics_without_bci = calculate_metrics(df_merge, df_without_bci)\n",
    "metrics_with_bci = calculate_metrics(df_merge, df_with_bci)\n",
    "\n",
    "print_metrics(metrics_without_bci, \"AR(1) without BCI\")\n",
    "print_metrics(metrics_with_bci, \"AR(1) with BCI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
